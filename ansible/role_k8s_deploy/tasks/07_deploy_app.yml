---
- name: Deploy web page(run in master)
  block:
  - name: Create secret for Amazon Elastic Block Store (EBS) CSI driver
    shell: |
      kubectl delete secret aws-secret --namespace kube-system
      key=$(sed -r '2!d;s/.*=//' .aws/credentials)
      access_key=$(sed -r '3!d;s/.*=//' .aws/credentials)
      kubectl create secret generic aws-secret \
        --namespace kube-system \
        --from-literal "key_id=${key}" \
        --from-literal "access_key=${access_key}"
    #sed - take 2 and 3 line and delete everything before "=" including "="
    #need .aws/credentials(02_init_master.yml)

  - name: Install Amazon Elastic Block Store (EBS) CSI driver
    shell: kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.24"

  - name: Copy files to master from localhost to deploy all
    copy:
      src: helm
      dest: $HOME

  - name: Install Cert-manager
    become: false
    shell: |
      helm repo add jetstack https://charts.jetstack.io
      helm repo update
      helm upgrade --install cert-manager jetstack/cert-manager \
        --namespace cert-manager --create-namespace --version v1.13.1 \
        --set installCRDs=true 
    #  --set webhook.hostNetwork=true --set webhook.securePort=10260
    ignore_errors: true    

  - name: Generate values.yaml
    template: 
      src: values.j2
      dest: $HOME/helm/web/values.yaml

  - name: Generate pvc-pv-prometheus.yaml
    template: 
      src: pvc-pv-prometheus.j2
      dest: $HOME/helm/prometheus/templates/pvc-pv-prometheus.yaml

  - name: Prepare cm-prometheus-rule.yaml
    shell: |
      sed -i 's/prefix/{{ prefix_from_terraform }}/' $HOME/helm/prometheus/templates/cm-prometheus-rule.yaml
      sed -i 's/domain/{{ domain_from_terraform }}/' $HOME/helm/prometheus/templates/cm-prometheus-rule.yaml

  - name: Delete secret key for pull image(if it exist)
    shell: kubectl delete secret regcred --ignore-not-found -n my-project

  - name: Create secret for pull image
    shell: |
      kubectl create namespace my-project
      kubectl create secret docker-registry regcred --docker-username=AWS \
        --docker-server={{ aws_user_id_from_terraform }}.dkr.ecr.{{ region_from_terraform }}.amazonaws.com \
        --docker-password=$(aws ecr get-login-password --region {{ region_from_terraform }}) -n my-project

  - name: Run deploy and service
    shell: |
      cd helm/web/
      while ! helm upgrade --install -n my-project --create-namespace test .; do sleep 5; done
    #will run until success(while Ingress-Nginx Controller will run)

  - name: Change app-password in cm-alert.yaml for email and token for Telegram
    shell: |
      sed -i "s/app-password/$(sed '1!d' \.alert\/secret-key.txt)/" helm/alertmanager/templates/cm-alert.yaml
      sed -i "s/token-telegram/$(sed '2!d' \.alert\/secret-key.txt)/" helm/alertmanager/templates/cm-alert.yaml
    #need .alert/secret-key.txt(02_init_master.yml)

  - name: Run Prometheus
    shell: |
      cd helm/prometheus/
      while ! helm upgrade --install -n monitoring --create-namespace prometheus .; do sleep 5; done

  - name: Run Node exporter
    shell: kubectl apply -f helm/node-exporter/node-exporter.yaml

  - name: Run Kube-state-metrics
    shell: |
      helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
      helm repo update
      helm upgrade --install -n monitoring kube-state-metrics prometheus-community/kube-state-metrics
#      kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

  - name: Run Alertmanager
    shell: |
      cd helm/alertmanager/
      helm upgrade --install -n monitoring alertmanager .

  - name: Run Blackbox
    shell: |
      cd helm/blackbox/
      helm upgrade --install -n monitoring blackbox .

  - name: Run Grafana
    shell: |
      cd helm/grafana/
      helm upgrade --install -n monitoring --create-namespace grafana .

  #- name: Set DeleteOnTermination in "true" on volume created of Prometheus to be one will delete when we run command terraform destroy
  #  #if this command doesn't run you need to delete the volume in AWS manually
  #  shell: |
  #    while ! aws ec2 modify-instance-attribute --instance-id \
  #      $(aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --query 'Volumes[0].Attachments[0].InstanceId' --output text --region {{ region_from_terraform }}) \
  #      --block-device-mappings "[{\"DeviceName\": \
  #      \"$(aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --query 'Volumes[0].Attachments[0].Device' --output text --region {{ region_from_terraform }})\",\
  #      \"Ebs\":{\"DeleteOnTermination\":true}}]" --region {{ region_from_terraform }}; do sleep 5; done

  - name: Approve CSRs(to see 04_cert_kudeadm.yml)
    shell: for csr_name in $(kubectl get csr | grep -i pending | awk '{print $1}'); do kubectl certificate approve $csr_name; done

  - name: Get volume ID created of Prometheus and ip addresses of workers where running Prometheus
    shell: |
      echo $(aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --query "Volumes[0].VolumeId" --output text --region {{ region_from_terraform }}) > name_worker.txt
      echo $(kubectl get po $(kubectl get po -A | grep prometheus | awk '{print $2}') -n monitoring -o jsonpath='{.spec.nodeName}') >> name_worker.txt
      echo $(kubectl get po $(kubectl get po -A | grep grafana | awk '{print $2}') -n monitoring -o jsonpath='{.spec.nodeName}') >> name_worker.txt

  - name: Copy name_worker.txt from master to localhost
    become: false
    fetch:
      src: $HOME/name_worker.txt
      dest: name_worker.txt
      flat: yes 

  - name: Create output file with ip addresses of workers where running Prometheus, volume ID created of Prometheus and domain name
    shell: |
      cp {{ role_path }}/files/output.txt output.txt
      sed -i "s/volume_id/$(sed '1!d' name_worker.txt)/" output.txt
      prom=$(sed -n 's/^'"$(sed '2!d' name_worker.txt)"'.*=//p' hosts)
      sed -i "s/prometheus_addr/$prom/" output.txt
      graf=$(sed -n 's/^'"$(sed '3!d' name_worker.txt)"'.*=//p' hosts)
      sed -i "s/grafana_addr/$graf/" output.txt
      sed -i "s/domain/{{ domain_from_terraform }}/" output.txt
    delegate_to: localhost

  - name: Check update DNS Records
    shell: while ! nslookup nginx.{{ domain_from_terraform }}; do sleep 5; done
    register: rc_check
  become: false
  #if run with become: true(in ansible.cfg) then %HOME will be /root and all run will be as root  
  when: "'ansible_master' in group_names"  

- name: Run in workers
  block:
  - name: Reload configuration of Prometheus(if you've run terraform already and not run destroy before)
    shell: for (( i=1; i<=5; i++)); do curl -X POST localhost:9090/-/reload; if [ $? == 0 ]; then break; fi; sleep 10; done
    args:
      executable: /usr/bin/bash
    ignore_errors: true
    #do 5 time with delay 10 seconds - wait to pod deploy
    #if [ $? == 0 ] - if command didn't work successfully and pass 50 seconds this worker doesn't have this pod
    #executable: /usr/bin/bash - default - /bin/sh - "for (( ))" doesn't work
  - name: Reload configuration of Alertmanager(if you've run terraform already and not run destroy before)
    shell: for (( i=1; i<=2; i++)); do pgrep alertmanager | sudo xargs kill -HUP; if [ $? == 0 ]; then break; fi; sleep 10; done
    args:
      executable: /usr/bin/bash    
    ignore_errors: true

  - name: Reload configuration of Blackbox(if you've run terraform already and not run destroy before)
    shell: for (( i=1; i<=2; i++)); do pgrep blackbox | sudo xargs kill -HUP; if [ $? == 0 ]; then break; fi; sleep 10; done
    args:
      executable: /usr/bin/bash    
    ignore_errors: true   
  when: "'ansible_workers' in group_names"       